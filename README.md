# The Identification Game - Group Poisson

Image classification is the process of taking an input image and predicting a class for it. A convolutional neural network (CNN) is able to classify images. CNNs have a number of early layers dedicated to extracting and learning general features, and then deeper fully connected layers dedicated to learning the specific class of an image based on detected features. CNNs are an example of deep learning and as such require very large datasets to prevent overfitting. In our case, we have used transfer learning, data augmentation and regularization to mitigate the fact that we had only 500 images available per class.

This project implements Natural Images classification using transfer learning and ensemble learning. A pytorch-based tool is devised for training the classifier. It allows users to decide which model architecture to conduct finetuning or feature extraction.The tool provides four [pre-trained models](https://pytorch.org/docs/stable/torchvision/models.html) to train a classifier: 'ResNet18', 'ResNet50', 'GoogleNet' and 'Inception-v3'. The predictor performance is evaluated by [f1 score](https://en.wikipedia.org/wiki/F1_score) in this project. 

### Dataset

Our data comes as a zip file which contains two directories, 'test' and 'train'. We have not included the dataset in this repository as github is not designed for large static storage. Instead, a user wishing to train or test our models should create a ./train/ or ./test/ directory in PoissoNet.

For the training set, the 'train' directory gives class label and the corresponding images set. Concretely, it is a dataset consisting of **100k** images categorized into **200** classes. Each image is of size **64x64 with RGB channels**.

For the testing set, there is only one directory inside the test file - images. Inside this directory, there are **10000** images without labels. The program will output a csv file that assigns labels to each of these JPEG images.

### Requirements
- Python:
  - python 3.7
- Python packages:
  - pycm, livelossplot, albumentations, torch, torchvision, sklearn...

### Installation Guide

To install the tool, run pip install on a machine that has Git installed on it:

```
python -m pip install git https://github.com/acse-2019/acse4-4-poisson.git
```

### User Instructions

[PoissoNet](https://github.com/acse-2019/acse4-4-poisson/tree/master/PoissoNet) folder direct the user to three ```.ipynb``` files.

**Mean and std finder.ipynb**
* To calculate the mean and standard deviation to help with dataset normalisation.

**Trainer.ipynb**
* User needs to choose one pre-trained model to train a classifier. One can define the number of layers that will be freezed and decide if using Albumentations to implement data augmentation. When choosing the ```Inception_v3```, user needs to decide whether to keep the auxiliary output. Note that the input size is 299 for ```Inception_v3``` and is 224 for all other three models.

**Predictor.ipynb**
* Once having trained your model (or if you wish to use one of our trained models), run this ipynb to generate predictions for every image in the ``` ./test/ ``` directory. By default you can choose whether to run our inception model with [Test Time Augmentation (TTA)](https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d) or whether you want to follow an ensemble approach and average the predictions from an Inception model and a ResNet model. The file also makes it easy to average more models or perform TTAs on any model.


### Documentation

The code includes [Sphinx](https://www.sphinx-doc.org) documentation. On systems with Sphinx installed, this can be built by running

```
python -m sphinx docs html
```

then viewing the `index.html` file in the `html` directory in your browser.

For systems with [LaTeX](https://www.latex-project.org/get/) installed, a manual pdf can be generated by running

```
python -m sphinx  -b latex docs latex
```

Then following the instructions to process the `Poisson.tex` file in the `latex` directory in your browser.

### Classifier Performance
The programme has performed data augmentation as well to prevent overfitting. The resulting accuracy rates imply that with appropriate amount of transformation, such as right-left flip and random rotation, variance could be reduced. The predictor that gives the best f1 score in this project is a combined-model classifier using Inception-v3 and ResNet18. 

Best Three Models with f1 Score:
* Inception-v3 with ResNet18: 0.79011
* Inception-v3 with TTA: 0.78313
* Average of GoogleNet, ResNet18 and ResNet50: 0.77400
